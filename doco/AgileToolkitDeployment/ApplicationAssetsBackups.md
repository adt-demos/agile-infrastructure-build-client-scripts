If you have multiple webservers running (which you must have for a resiliant production setup), then, you will likely have chosen the option to use your S3 based datastore as a shared directory system for your assets which is mounted in your application's media directories on each server as a shared file system using s3fs.
Your appilcation assets are stored in one place in the requisite s3 bucket which has a very large data capacity which means you can run your application to the point where it has terrabytes of images or other media and still not run out of space (assuming you can afford it of course, some providers are more pricey than others). On Amazon based deployments you have the option of using EFS instead of S3 to store you assets. Either way, this is the only copy of your assets which means you need a replication or a backup strategy.

There are two scripts which run on the webserver to make backups of the assets buckets within your object storage service. One script is for EFS based assets and the other is for assets stored in S3. You have the option to modify the cron script to switch these processes off on each webserver and the processes will only sync new and updated files. 
If you want to be super safe with your application assets backups, you can manually sync or backup your S3 buckets or EFS filesystems to external local storage. This is recommended best practice, but, it does mean an administrative procedure.

The assets buckets are synchronised to backup buckets daily and I am not sure what the cost metrics would be if you had a very large set of application assets, so you might want to review that. 
